{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d1ffbc",
   "metadata": {},
   "source": [
    "### Quick Guide to Using Jupyter Notebooks\n",
    "\n",
    "- A notebook is made up of **cells**, which can contain either code (Python) or text (Markdown).  \n",
    "- To run a cell, select it and press **Shift + Enter** (or the ▶️ button in the toolbar).  \n",
    "- Variables you define in one cell remain **alive in memory** until you restart the kernel.  \n",
    "- Cells can be executed in any order, but running them **sequentially from top to bottom** is usually the safest way.  \n",
    "- If results look inconsistent, you can **restart the kernel** (from the Kernel menu) and re-run the cells.  \n",
    "\n",
    "---\n",
    "\n",
    "ℹ️ For a more detailed introduction to Jupyter notebooks, see the [Jupyter documentation](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html) or the [official tutorial](https://jupyter.org/try).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb0636c",
   "metadata": {},
   "source": [
    "### Machine learning and beam management\n",
    "\n",
    "Millimeter-wave (mmWave) communication systems rely on narrow beams to achieve sufficient receive signal power. Adjusting these beams is typically associated with a **large measuremnt overhead** as the standard procedure is to try all pre-defined directions and selecting the one with highest received signal power.\n",
    "\n",
    "Beam selection can benefit from the knowledge of **user positions, coupled with machine learning techniques**, to reduce the overhead in mm Wave beam training.\n",
    "\n",
    "In this example we will use real-world data from the DeepSense6G dataset (https://www.deepsense6g.net) that contains\n",
    "positions measurements obtained by commercial-off-the-shelf GPS. For each **GPS position we will have an associated vector of received powers for each of the 64 pre-defined directions.**\n",
    "\n",
    "We will start by exploring and processing the data and continue with the design and implementation of a basic neural network to predict the best direction given a gps position. \n",
    "\n",
    "This lab is partly based on [1] and [2]\n",
    "\n",
    "[1] Morais, J., Bchboodi, A., Pezeshki, H. and Alkhateeb, A., 2023, May. Position-aided beam prediction in the real world: How useful GPS locations actually are?. In ICC 2023-IEEE International Conference on Communications (pp. 1824-1829). IEEE.\n",
    "\n",
    "[2] D. Cometti, S. Mazuelas, G. Sacco, N. Blefari-Melazzi, and S. Bartoletti, “Location-Aided Iterative Beam Search via Learning-based Generative Models,” in Proc. IEEE Int. Conf. Commun. (ICC) Workshops, accepted for publication, June 2025.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac347d56",
   "metadata": {},
   "source": [
    "## Clone the repository by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf852ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup: clone lab repo and enter it ---\n",
    "!git clone https://github.com/dontolon/ml_beam_management_lab.git\n",
    "%cd ml_beam_management_lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea82e85",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c046d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy>=1.22 pandas>=1.5 matplotlib>=3.6 torch>=2.0 scikit-learn>=1.2 utm>=0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14f21bb",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from helper_scripts.load_data import normalize_pos, min_max, build_mlp, run_epoch, evaluate, make_client_loaders, plot_client_split,split_noniid_label_dirichlet,split_iid_equal_indices, _normalize_for_plot, get_state_dict,set_state_dict,local_train_on_client,fedavg,sample_clients_indices,federated_round\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea3a0c",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "\n",
    "We will import and load scenario 2 from the DeepSense6G dataset (https://www.deepsense6g.net/scenario-2/) \n",
    "\n",
    "This scenario emulates a Vehicle-to-Infrastructure (V2I) mmWave communication setup. \n",
    "\n",
    "We consider a system where a base station (BS) with $N$ antennas communicates with a single-antenna UE using one of the $M$ beamforming vectors $\\mathbf{f}_m \\in \\mathbb{C}^{N \\times 1}$ present in its codebook \n",
    "$\\mathcal{F} = \\{\\mathbf{f}_m\\}_{m=1}^M$.\n",
    "\n",
    "In our case:  \n",
    "- $M = 64$ beamforming vectors,  \n",
    "- $N = 16$ antennas at the BS,  \n",
    "- carrier frequency is **60 GHz**.  \n",
    "\n",
    "#### Video\n",
    "\n",
    "You can watch a quick video on the data gathering process here https://www.youtube.com/watch?v=67mehcyByLU&t=5s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a3edf",
   "metadata": {},
   "source": [
    "![](../images/g66-1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3158b9cf",
   "metadata": {},
   "source": [
    "#### Select the scenario by changing the scenario flag in either \"SIMPLE\" (SCENARIO 2) or \"COMPLEX\" (SCENARIO 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select scenario\n",
    "scenario = \"SIMPLE\"   # change to \"HARD\" for scenario 4\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "\n",
    "if scenario == \"SIMPLE\":\n",
    "    BS_location = np.array([[33.42034722222222, -111.92915277777779]])\n",
    "    UE_locations = np.load(DATA_DIR / \"scenario2_unit2_loc_1-2974.npy\")[:, :2]\n",
    "    beam_powers  = np.load(DATA_DIR / \"scenario2_unit1_pwr_60ghz_1-2974.npy\")\n",
    "\n",
    "elif scenario == \"COMPLEX\":\n",
    "    BS_location = np.array([[33.41820833333333, -111.92610277777779]])\n",
    "    UE_locations = np.load(DATA_DIR / \"scenario4_unit2_loc_1-1867.npy\")[:, :2]\n",
    "    beam_powers  = np.load(DATA_DIR / \"scenario4_unit1_pwr_60ghz_1-1867.npy\")\n",
    "\n",
    "print(f\"Scenario {scenario} loaded:\")\n",
    "print(\"BS_location:\", BS_location.shape)\n",
    "print(\"UE_locations:\", UE_locations.shape)\n",
    "print(\"beam_powers:\", beam_powers.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4135672",
   "metadata": {},
   "source": [
    "#### Preparing the data: BS and UE positions\n",
    "\n",
    "In this step, we prepare the spatial data before visualization and modeling:\n",
    "\n",
    "- We **stack** the base station (BS) and user equipment (UE) positions together into one array.  \n",
    "- We then apply **min–max normalization** across all coordinates so that the BS and UE positions are represented in a comparable, normalized coordinate system between 0 and 1.  \n",
    "\n",
    "This ensures that:\n",
    "- Both BS and UE positions are expressed on the same scale.  \n",
    "- Visualization and downstream models (e.g., beam selection models) are not biased by raw latitude/longitude magnitudes.  \n",
    "\n",
    "After normalization:\n",
    "- The **first row** corresponds to the BS.  \n",
    "- The **remaining rows** correspond to the UEs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack BS and UEs together\n",
    "all_positions = np.vstack([BS_location, UE_locations])  # (1+N, 2)\n",
    "\n",
    "# Min-max normalize everything\n",
    "all_norm = min_max(all_positions, axis=0)\n",
    "\n",
    "# First row is BS, rest are UEs\n",
    "BS_norm = all_norm[0:1]\n",
    "UE_norm = all_norm[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ff0e3",
   "metadata": {},
   "source": [
    "#### Visualizing the normalized positions\n",
    "\n",
    "Here, we create a scatter plot to visualize the **normalized positions** of the BS and UEs:\n",
    "\n",
    "- The BS is shown as a red star.  \n",
    "- The UEs are shown as small blue dots.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized positions\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(UE_norm[:,0], UE_norm[:,1], c=\"blue\", s=8, label=\"UEs\")\n",
    "plt.scatter(BS_norm[0,0], BS_norm[0,1], c=\"red\", marker=\"*\", s=200, label=\"BS\")\n",
    "plt.xlabel(\"Normalized Lat\")\n",
    "plt.ylabel(\"Normalized Long\")\n",
    "plt.title(\"UE positions + BS (min–max normalized together)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a9121",
   "metadata": {},
   "source": [
    "#### Exploring beam power profiles \n",
    "\n",
    "Let's randomly pick one sample from the dataset and explore:\n",
    "\n",
    "1. **Beam power profile (left plot):**  \n",
    "   - Shows the received power values across all 64 beams for the chosen UE.  \n",
    "   - Index with the highest received power value.\n",
    "   \n",
    "2. **Spatial view (right plot):**  \n",
    "   - Shows all normalized UE positions (blue dots).  \n",
    "   - The BS is marked with a red star.  \n",
    "   - The randomly selected UE is highlighted in orange. \n",
    "\n",
    "Run the plot multiple times to get the intuition behind why GPS positions can allow us to predict the best beam index. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd82fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize beam power profile for a random UE\n",
    "\n",
    "idx = np.random.randint(0, beam_powers.shape[0])\n",
    "powers = beam_powers[idx]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14,5))\n",
    "best_idx = np.argmax(powers)\n",
    "\n",
    "# --- Left: beam power profile ---\n",
    "axes[0].plot(range(1, len(powers)+1), powers, marker=\"o\")\n",
    "axes[0].axvline(best_idx+1, color=\"red\", linestyle=\"--\", label=f\"Best beam {best_idx+1}\")\n",
    "axes[0].set_xlabel(\"Beam index (1–64)\")\n",
    "axes[0].set_ylabel(\"Power value\")\n",
    "axes[0].set_title(f\"UE {idx}: Power across beams\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# --- Right: spatial scatter ---\n",
    "axes[1].scatter(UE_norm[:,0], UE_norm[:,1], c=\"blue\", s=8, label=\"UEs\")\n",
    "axes[1].scatter(BS_norm[0,0], BS_norm[0,1], c=\"red\", marker=\"*\", s=200, label=\"BS\")\n",
    "axes[1].scatter(UE_norm[idx,0], UE_norm[idx,1], c=\"orange\", edgecolor=\"black\", s=80, label=\"Selected UE\")\n",
    "axes[1].set_xlabel(\"Normalized x\")\n",
    "axes[1].set_ylabel(\"Normalized y\")\n",
    "axes[1].set_title(\"UE positions + BS (selected UE highlighted)\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1602fe3f",
   "metadata": {},
   "source": [
    "#### Constructing the beam prediction dataset\n",
    "\n",
    "So far, we’ve visualized single UEs and their beam power profiles.  \n",
    "Now we take the next step: create the dataset for supervised learning.\n",
    "\n",
    "- For each sample, we find its **best beam index**:  \n",
    "$$\n",
    "m^* = \\arg\\max_{m \\in \\{1, \\dots, M\\}} \\; \\text{beam\\_powers}_{m},\n",
    "$$\n",
    "\n",
    "- We then define:  \n",
    "  - **Features (X):** the normalized UE positions (shape = (N, 2))  \n",
    "  - **Labels (y):** the best beam index for each sample (shape = (N,))  \n",
    "\n",
    "This dataset \\((X, y)\\) is the starting point for training models to **predict the best beam** from position information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best beam index for each UE and create dataset\n",
    "\n",
    "best_beam = np.argmax(beam_powers, axis=1)\n",
    "X = UE_norm      # shape (N,2)\n",
    "y = best_beam    # shape (N,)\n",
    "\n",
    "print(\"Dataset created:\")\n",
    "print(\"X:\", X.shape, \"y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a751406",
   "metadata": {},
   "source": [
    "#### Visualizing spatial patterns of best beams\n",
    "\n",
    "Now that we have constructed the dataset \\((X, y)\\), we can visualize how the **best beam index** varies across space:\n",
    "\n",
    "- Each sample is plotted at its normalized position \\((x, y)\\).  \n",
    "- The color encodes the **best beam index** \\(m^*\\).  \n",
    "- The colorbar on the right shows the mapping from color → beam index.  \n",
    "\n",
    "This plot lets us see the **spatial partitioning of beams**:  \n",
    "- Neighboring samples often share the same best beam.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7040c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UE positions colored by best beam\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sc = plt.scatter(X[:,0], X[:,1], c=y, cmap=\"viridis\", s=8)\n",
    "plt.colorbar(sc, label=\"Best beam index\")\n",
    "plt.xlabel(\"Normalized x\")\n",
    "plt.ylabel(\"Normalized y\")\n",
    "plt.title(f\"UE positions colored by best beam ({scenario} scenario)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a456acf",
   "metadata": {},
   "source": [
    "#### Preparing the dataset for PyTorch\n",
    "\n",
    "Now that we have the feature matrix $X$ (UE positions) and the labels $y$ (best beam indices), we need to prepare them for training a neural network in PyTorch.\n",
    "\n",
    "Steps:\n",
    "1. **Convert to tensors:**  \n",
    "   - `X_tensor`: the input features (shape: $N \\times 2$).  \n",
    "   - `y_tensor`: the target labels (shape: $N$, with values in $\\{0, \\dots, M-1\\}$).\n",
    "\n",
    "2. **Bundle into a dataset:**  \n",
    "   - `TensorDataset` combines the inputs and labels into a format that PyTorch understands.\n",
    "\n",
    "3. **Wrap with a DataLoader:**  \n",
    "   - Handles batching (here: 128 samples per batch).  \n",
    "   - Shuffles the data each epoch for better generalization.  \n",
    "   - Makes it easy to iterate over the dataset in training loops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4833e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Bundle into a dataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Create a DataLoader (mini-batches)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(\"Dataset ready for NN training!\")\n",
    "print(\"Number of batches:\", len(loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00122c52",
   "metadata": {},
   "source": [
    "### Splitting the dataset into train/validation/test\n",
    "\n",
    "To properly train and evaluate our model, we need to split the dataset into three parts:\n",
    "\n",
    "1. **Training set (70%)**  \n",
    "   - Used by the neural network to learn the mapping from UE positions → best beam indices.\n",
    "\n",
    "2. **Validation set (15%)**  \n",
    "   - Used to tune hyperparameters and prevent overfitting.  \n",
    "   - The model never directly trains on this data.\n",
    "\n",
    "3. **Test set (15%)**  \n",
    "   - Held out until the very end.  \n",
    "   - Used to evaluate the *true generalization performance*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0149374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/val/test with a 70/15/15 ratio\n",
    "\n",
    "# 70/30 split first\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Then split 30 into 15/15\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:  \", X_val.shape, y_val.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "def make_loader(X, y, batch_size=32, shuffle=False):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "    return DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_loader = make_loader(X_train, y_train, batch_size=32, shuffle=True)\n",
    "val_loader   = make_loader(X_val,   y_val,   batch_size=32)\n",
    "test_loader  = make_loader(X_test,  y_test,  batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a13681",
   "metadata": {},
   "source": [
    "### Building the model and training components\n",
    "\n",
    "The helper function `build_mlp(...)` constructs not only the neural network architecture, but also the essential components for training:\n",
    "\n",
    "- **Model:** a configurable MLP with user-defined depth, width, and activation.  \n",
    "- **Loss function (criterion):** categorical cross-entropy, suitable for multi-class classification.  \n",
    "- **Optimizer:** Adam, with configurable learning rate.  \n",
    "- **Scheduler:** a multi-step learning rate scheduler that reduces the learning rate by a factor $\\gamma$ at predefined milestones.\n",
    "\n",
    "\n",
    "### Hyperparameter tuning\n",
    "\n",
    "- Try and change each parameter to see how it affects training \n",
    "- What is the highest top-1 accuracy you can achieve? Top-10?\n",
    "- How many epochs are necessary to reach acceptable results with your neural network architecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d07ed",
   "metadata": {},
   "source": [
    "**RERUN THE 2 CELLS BELOW FOR YOUR CHANGES TO TAKE EFFECT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39679cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model and training components\n",
    "\n",
    "model, criterion, optimizer, scheduler = build_mlp(\n",
    "    input_dim=2,\n",
    "    output_dim=64,\n",
    "    hidden_dim=16,\n",
    "    hidden_layers=1,\n",
    "    activation=\"ReLU\",\n",
    "    lr=1e-8,\n",
    "    milestones=[20, 40],\n",
    "    gamma=0.2,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5028c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to tune\n",
    "\n",
    "# Number of training rounds\n",
    "EPOCHS = 20\n",
    "# Top-k values for evaluation\n",
    "k_values = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a0458a",
   "metadata": {},
   "source": [
    "#### Training loop and evaluation protocol\n",
    "\n",
    "We now implement the complete training and evaluation routine for the beam prediction model.\n",
    "\n",
    "**1. Training step (`run_epoch`)**\n",
    "- Iterates over one pass of the dataset (an epoch).  \n",
    "- Sets the model to training or evaluation mode.  \n",
    "- For each mini-batch:\n",
    "  - Computes forward pass (`out = model(xb)`).  \n",
    "  - Evaluates the loss using categorical cross-entropy.  \n",
    "  - If training:\n",
    "    - Clears gradients (`optimizer.zero_grad()`).  \n",
    "    - Backpropagates (`loss.backward()`).  \n",
    "    - Updates parameters (`optimizer.step()`).  \n",
    "- Tracks average loss and top-1 accuracy for the epoch.\n",
    "\n",
    "**2. Evaluation step (`evaluate`)**\n",
    "- Runs the model in inference mode (no gradient computation).  \n",
    "- Computes **top-k accuracies** for several values of \\(k\\) (1, 3, 5, 10):  \n",
    "  - For each sample, checks whether the ground-truth beam index appears among the model’s top-\\(k\\) predicted beams.  \n",
    "- Returns a dictionary mapping \\(k \\mapsto \\text{accuracy}\\).\n",
    "\n",
    "**3. Training loop**\n",
    "- Repeats for a fixed number of epochs (here, 60).  \n",
    "- Each epoch:\n",
    "  - Calls `run_epoch` on the training set.  \n",
    "  - Evaluates on the validation set using `evaluate`.  \n",
    "  - Updates the learning rate via the scheduler.  \n",
    "- Records the training history (loss, accuracy) and validation metrics.  \n",
    "- Periodically prints progress (every 10 epochs, and during the first 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84abab0",
   "metadata": {},
   "source": [
    "**WHEN TRYING DIFFERENT ARCHITECTURES AND HYPERPARAMETERS RE RUN THE 2 CODING CELLS ABOVE TO APPLY THE CHANGES BEFORE RETRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN TRAINING LOOP\n",
    "\n",
    "train_hist, val_hist = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, model, optimizer, criterion, train=True) # <-- get train loss, acc\n",
    "    va_loss, va_acc = run_epoch(val_loader, model, optimizer, criterion, train=False)   # <-- get val loss, acc\n",
    "    val_metrics = evaluate(val_loader, model, k_values=k_values)\n",
    "    scheduler.step()\n",
    "    train_hist.append((tr_loss, tr_acc))\n",
    "    val_hist.append((va_loss, va_acc, val_metrics))   # save loss + accs\n",
    "\n",
    "    if (epoch+1) % 10 == 0 or epoch < 5:\n",
    "        print(f\"Epoch {epoch+1:02d}: Train loss {tr_loss:.3f}, Val loss {va_loss:.3f}, \"\n",
    "              f\"Train acc {tr_acc:.3f}, Val top-1 {val_metrics[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e772976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss curves\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot([tr[0] for tr in train_hist], label=\"Train Loss\")\n",
    "plt.plot([vh[0] for vh in val_hist], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#grid\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final model on validation or test set\n",
    "final_metrics = evaluate(test_loader, model, k_values=k_values)\n",
    "\n",
    "# Prepare data\n",
    "x_vals = list(final_metrics.keys())\n",
    "y_vals = [final_metrics[k] for k in x_vals]\n",
    "\n",
    "# Line plot\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(x_vals, y_vals, marker=\"o\", linestyle=\"-\", color=\"blue\")\n",
    "plt.xticks(x_vals)\n",
    "plt.ylim(0,1)\n",
    "#grid\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.xlabel(\"k value (Top-k)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Final Top-k Accuracies on Test Set\")\n",
    "\n",
    "# Annotate each point with accuracy value\n",
    "for x, y in zip(x_vals, y_vals):\n",
    "    plt.text(x, y+0.01, f\"{y:.2f}\", ha=\"center\")\n",
    "\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8aba6f",
   "metadata": {},
   "source": [
    "### Extra: Federated Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f1984",
   "metadata": {},
   "source": [
    "## Introduction to Federated Learning\n",
    "\n",
    "In centralized training, all data is collected in a single place and the model is trained directly on it.  \n",
    "In **federated learning (FL)**, the data remains distributed across many clients (e.g., devices, sensors, or users).  \n",
    "\n",
    "The process works as follows:\n",
    "1. The server sends a **global model** to the clients.  \n",
    "2. Each client trains the model locally on its own data.  \n",
    "3. Clients send back **updates** (not raw data) to the server.  \n",
    "4. The server **aggregates** these updates (e.g., with FedAvg) to form a new global model.  \n",
    "5. Steps 1–4 repeat for several **rounds**.  \n",
    "\n",
    "This setup preserves **data privacy** (since data never leaves the client) and allows training across **heterogeneous datasets**, but also makes optimization more challenging compared to centralized training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654673f",
   "metadata": {},
   "source": [
    "![](../images/Federated-Learning-(1).png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643c3c3a",
   "metadata": {},
   "source": [
    "###  IID vs Non-IID client splits\n",
    "\n",
    "In federated learning, how data is divided among clients strongly affects training:\n",
    "\n",
    "- **IID split (uniform & equal):**  \n",
    "  Each client receives roughly the same number of samples, drawn randomly from the whole dataset.  \n",
    "  → Clients look very similar, which makes federated learning easier.\n",
    "\n",
    "- **Non-IID (size skew):**  \n",
    "  Clients receive **different numbers of samples** (using a Dirichlet distribution over client sizes).  \n",
    "  Some clients get lots of data, others very little.  \n",
    "  → Simulates devices with unbalanced participation (e.g., some phones sending many updates, others rarely).\n",
    "\n",
    "- **Non-IID (label skew):**  \n",
    "  Clients receive **different proportions of labels/classes** (using Dirichlet over labels).  \n",
    "  Some clients may mostly see certain beams, while others mostly see different beams.  \n",
    "  → Simulates devices collecting biased data (e.g., users always in certain areas of the network).\n",
    "\n",
    "Having both kinds of non-IID splits make the federated learning problem harder and more realistic.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01290c5",
   "metadata": {},
   "source": [
    "### IID client split\n",
    "\n",
    "In this step, we divide the dataset into **IID (Independent and Identically Distributed)** partitions.  \n",
    "That means each client receives roughly the **same number of samples**, drawn uniformly at random from the dataset.  \n",
    "\n",
    "The plot below shows:  \n",
    "- **Samples** → UE positions belonging to different clients (each client has its own color).  \n",
    "- **Red star** → the base station (BS).  \n",
    "\n",
    "This split simulates the case where **all clients have balanced data**, which is the \"easiest\" setting for federated learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2d354b",
   "metadata": {},
   "source": [
    "# YOU MUST RERUN THE CELL BELOW EVERY TIME YOU MAKE CHANGES TO THE CLIENT SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels from powers\n",
    "best_beam = np.argmax(beam_powers, axis=1)\n",
    "\n",
    "# Features (normalized positions)\n",
    "X = UE_norm\n",
    "y = best_beam\n",
    "\n",
    "# --- Keep track of indices too ---\n",
    "idx_all = np.arange(len(y))\n",
    "\n",
    "# Train / temp split\n",
    "train_idx, temp_idx = train_test_split(\n",
    "    idx_all, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Val / test split\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Now slice arrays\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_val,   y_val   = X[val_idx],   y[val_idx]\n",
    "X_test,  y_test  = X[test_idx],  y[test_idx]\n",
    "\n",
    "N = len(y_train)\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:  \", X_val.shape, y_val.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86828ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS TO DECIDE THE NUMBER OF CLIENTS IN THE IID SPLIT\n",
    "num_clients_iid = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b2fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have to rerun the first cell in the federated part to avoid any errors.\n",
    "\n",
    "clients_iid = split_iid_equal_indices(N, num_clients=num_clients_iid, seed=0)\n",
    "\n",
    "plot_client_split(\n",
    "    UE_locations[train_idx],   # use training subset only\n",
    "    clients_iid,\n",
    "    BS_location=BS_location,\n",
    "    normalize=True,\n",
    "    title=f\"IID equal-sized split ({num_clients_iid} clients)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b611f6",
   "metadata": {},
   "source": [
    "### Non-IID split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebe244",
   "metadata": {},
   "source": [
    "### Dirichlet-based Non-IID splits\n",
    "\n",
    "The function `split_noniid_label_dirichlet` can create different federated data splits depending on its parameters:\n",
    "\n",
    "- **`alpha_sizes`** → controls *how balanced client dataset sizes are*.  \n",
    "  - Large → all clients get about the same number of samples.  \n",
    "  - Small → some clients get many samples, others very few.  \n",
    "  - It can be set to any positive real number\n",
    "\n",
    "- **`alpha_labels`** → controls *how mixed the labels/classes are inside each client*.  \n",
    "  - Large → each client sees a mix of all labels (IID-like).  \n",
    "  - Small → each client specializes in only a few labels (class skew).  \n",
    "  - It can be set to any positive real number\n",
    "\n",
    "\n",
    "By tuning these two parameters, you can simulate:\n",
    "- **IID data** → both alphas large  \n",
    "- **Size-skew non-IID** → small `alpha_sizes`, large `alpha_labels`  \n",
    "- **Label-skew non-IID** → large `alpha_sizes`, small `alpha_labels`  \n",
    "- **Combined skew** → both small  \n",
    "\n",
    "This lets us study how different data distributions across clients affect the performance of federated learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8655050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUNE BOTH ALPHAS HERE\n",
    "alpha_labels = 0.5\n",
    "alpha_sizes = 0.5\n",
    "# CHANGE THIS TO DECIDE THE NUMBER OF CLIENTS IN THE NON-IID SPLIT\n",
    "num_clients_noniid = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd21c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE THE SIZE SPLIT\n",
    "clients_noniid = split_noniid_label_dirichlet(\n",
    "    y_train, num_clients=num_clients_noniid,\n",
    "    alpha_labels=alpha_labels, alpha_sizes=alpha_sizes,\n",
    "    min_per_client=50, seed=0\n",
    ")\n",
    "\n",
    "plot_client_split(\n",
    "    UE_locations[train_idx],   # not the full UE_locations\n",
    "    clients_noniid,\n",
    "    BS_location=BS_location,\n",
    "    normalize=True,\n",
    "    title=f\"Non-IID size-skew split (Alpha Labels α={alpha_labels}, Alpha Sizes α={alpha_sizes}, {num_clients_noniid} clients)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1de166",
   "metadata": {},
   "source": [
    "### Make clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ea197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PICK IF YOU WANT TO USE IID OR NON-IID SPLIT\n",
    "# RE-RUN THE CELLS ABOVE IF YOU WANT TO RE-DEFINE THE SPLIT AND RUN THE FEDERATED LOOP\n",
    "\n",
    "chosen_split = clients_iid   # clients_iid or clients_noniid\n",
    "\n",
    "client_loaders = make_client_loaders(X_train, y_train, chosen_split, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac1189",
   "metadata": {},
   "source": [
    "### Federated framework hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c5743",
   "metadata": {},
   "source": [
    "### Federated learning hyperparameters\n",
    "\n",
    "The configuration below defines the main **training hyperparameters** for our federated setup:\n",
    "\n",
    "- **`rounds`** → number of **federated communication rounds**.  \n",
    "  In each round, clients train locally and then synchronize with the server.  \n",
    "  More rounds = longer training, but also higher accuracy (up to a point).  \n",
    "\n",
    "- **`local_epochs`** → number of **local training epochs per client** before sending updates.  \n",
    "  If this is large, clients learn more from their own data but risk **diverging** if the data is very different (non-IID).  \n",
    "  If this is small, clients communicate more often, which increases **communication cost**.  \n",
    "\n",
    "- **`lr` (learning rate)** → step size of the optimizer on each client.  \n",
    "  Higher values speed up learning but may cause instability.  \n",
    "  Lower values are more stable but require more rounds.  \n",
    "\n",
    "- **`weight_decay`** → regularization term that penalizes large weights (L2 regularization).  \n",
    "  Helps avoid overfitting, though in many FL setups this can be left at `0.0`.  \n",
    "\n",
    "By adjusting these hyperparameters, we can study the **trade-offs between accuracy, convergence speed, and communication efficiency** in federated learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55fd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated learning configuration to tune\n",
    "\n",
    "fed_cfg = {\n",
    "    \"rounds\": 20,\n",
    "    \"local_epochs\": 1,\n",
    "    \"lr\": 1e-8,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a054f7",
   "metadata": {},
   "source": [
    "### Model constructor (`model_ctor`)\n",
    "\n",
    "The function `model_ctor()` builds the a neural network, same method as the centralized training part:\n",
    "- **Input dimension = 2** (the normalized UE position `[x, y]`)\n",
    "- **Output dimension = 64** (the beam index classes)\n",
    "- **Hidden layers = 3**, each of size **256**, with **ReLU activations**\n",
    "\n",
    "It also sets up the **optimizer** and **scheduler** with the same hyperparameters (learning rate, milestones, decay rate) that we had in the centralized training.  \n",
    "\n",
    "The key difference is that in **federated learning**, this constructor is called **separately on each client**.  \n",
    "Each client starts from the **current global model weights**, trains locally, and then the server averages the updates (FedAvg).  \n",
    "\n",
    "To correctly compare between FEDERATED and CENTRALIZED frameworks use the same neural network architecture for both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40cccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define a model constructor function to create a new model instance for each client\n",
    "# This is important to ensure that each client starts with the same initial weights\n",
    "# and that the model architecture is consistent across clients\n",
    "\n",
    "def model_ctor():\n",
    "    # keep these hyperparams aligned with your centralized setup if you want to compare\n",
    "    return build_mlp(\n",
    "        input_dim=2,\n",
    "        output_dim=64,\n",
    "        hidden_dim=16,\n",
    "        hidden_layers=1,\n",
    "        activation=\"ReLU\",\n",
    "        lr=1e-8                 # local client LR\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the server/global model once DO NOT CHANGE\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "global_model, _, _, _ = model_ctor()\n",
    "global_model = global_model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbea243",
   "metadata": {},
   "source": [
    "### Federated training loop\n",
    "\n",
    "In this cell, we run the **federated training process**:\n",
    "\n",
    "- The loop runs for the number of **rounds** specified in `fed_cfg`.  \n",
    "- In each round:\n",
    "  1. All clients are selected.  \n",
    "  2. Each selected client trains the model locally for `local_epochs`.  \n",
    "  3. The server aggregates all client updates into a new **global model** (FedAvg).  \n",
    "- After each round, we evaluate the global model on the **validation set** and record its **Top-k accuracies**.  \n",
    "\n",
    "At the end of training, we evaluate the final global model on the **test set** and report the accuracies.  \n",
    "\n",
    "This mirrors the centralized loop, but instead of training on all data at once, we train **collaboratively across clients** with local updates + aggregation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1799cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_val_hist = []\n",
    "for r in range(1, fed_cfg[\"rounds\"] + 1):\n",
    "    _ = federated_round(\n",
    "        model=global_model,\n",
    "        model_ctor=model_ctor,\n",
    "        clients=client_loaders,\n",
    "        client_fraction=1,\n",
    "        local_epochs=fed_cfg[\"local_epochs\"],\n",
    "        seed=42 + r,\n",
    "    )\n",
    "    val_metrics = evaluate(val_loader, global_model, k_values=k_values)\n",
    "    fed_val_hist.append(val_metrics)\n",
    "    if r % 2 == 0 or r <= 3:\n",
    "        print(f\"[Round {r:02d}] Val top-1={val_metrics[1]:.3f}, \"\n",
    "              f\"top-3={val_metrics[3]:.3f}, top-5={val_metrics[5]:.3f}, top-10={val_metrics[10]:.3f}\")\n",
    "\n",
    "# Final test\n",
    "fed_test_metrics = evaluate(test_loader, global_model, k_values=k_values)\n",
    "print(\"Federated Test Accuracies:\", fed_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c7058",
   "metadata": {},
   "source": [
    "### Centralized vs Federated\n",
    "\n",
    "Now we have both centralized and federated results:\n",
    "\n",
    "1. **Effect of client splits**  \n",
    "   - Compare results with **IID** vs **non-IID** splits (size skew, label skew).  \n",
    "   - Which setting makes training harder? Why?\n",
    "\n",
    "2. **Local epochs vs communication rounds**  \n",
    "   - What happens if you increase `local_epochs`?  \n",
    "   - Is it better to do more local training per client, or more federated rounds?  \n",
    "   - How do these choices balance **accuracy vs communication cost**?\n",
    "\n",
    "3. **Centralized vs Federated**  \n",
    "   - Can federated training reach the **same performance** as centralized training? \n",
    "   - If yes, what are the parameters you chose?  \n",
    "   - If not, what’s missing? (e.g., full data access, reduced variance, more synchronization).\n",
    "\n",
    "4. **Number of clients**  \n",
    "   - Increase the number of clients. How does this affect performance?  \n",
    "   - Does having many small clients make training less stable?\n",
    "\n",
    "5. **Top-k accuracy trends**  \n",
    "   - How do Top-1 vs Top-3 vs Top-5 accuracies compare?  \n",
    "   - Why is it easier to achieve high Top-10 accuracy than high Top-1 accuracy?\n",
    "   - Does the federated implementation need more rounds in order to achieve the same Top-k accuracy as the centralized?\n",
    "\n",
    "**NOTE** Keep in mind that multiple runs with the same exact setup might produce different final accuracy and loss across runs\n",
    "\n",
    "Try changing one setting at a time, re-run the all federated cells if necessary , and observe how the plots change.  \n",
    "The goal is not just to get high accuracy, but to understand the **trade-offs** in federated learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49564e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performance Centralized vs Federated\n",
    "# Centralized\n",
    "x_vals = list(final_metrics.keys())\n",
    "y_central = [final_metrics[k] for k in x_vals]\n",
    "\n",
    "# Federated\n",
    "y_fed = [fed_test_metrics[k] for k in x_vals]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Centralized line\n",
    "plt.plot(x_vals, y_central, marker=\"o\", linestyle=\"-\", color=\"blue\", label=\"Centralized\")\n",
    "\n",
    "# Federated line\n",
    "plt.plot(x_vals, y_fed, marker=\"s\", linestyle=\"--\", color=\"green\", label=\"Federated\")\n",
    "\n",
    "# Styling\n",
    "plt.xticks(x_vals)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel(\"k value (Top-k)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Final Top-k Accuracies (Centralized vs Federated)\")\n",
    "plt.legend()\n",
    "\n",
    "# Annotate centralized points\n",
    "for x, y in zip(x_vals, y_central):\n",
    "    plt.text(x, y-0.04, f\"{y:.2f}\", ha=\"center\", color=\"blue\")\n",
    "\n",
    "# Annotate federated points\n",
    "for x, y in zip(x_vals, y_fed):\n",
    "    plt.text(x, y-0.04, f\"{y:.2f}\", ha=\"center\", color=\"green\")\n",
    "\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
